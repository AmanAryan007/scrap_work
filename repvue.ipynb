{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kAHTmeqLKN-"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def web_driver():\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--verbose\")\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--disable-gpu')\n",
        "    options.add_argument(\"--window-size=1920,1200\")\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
        "\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    return driver\n",
        "\n",
        "def process_url(url):\n",
        "    driver = web_driver()\n",
        "    try:\n",
        "        driver.get(url)\n",
        "        time.sleep(5)\n",
        "\n",
        "        # Click on the element to expand the description\n",
        "        xpath_expression = \"/html/body/div/main/div[2]/div/div[3]/div[3]/div[1]/div[1]/div/div[3]/p/span\"\n",
        "        element = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, xpath_expression)))\n",
        "        element.click()\n",
        "\n",
        "        # Wait for the description element to be visible\n",
        "        xpath_description = '//*[@id=\"company-container\"]/div[3]/div[3]/div[1]/div[1]/div/div[3]/p'\n",
        "        description_element = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.XPATH, xpath_description)))\n",
        "\n",
        "        # Extract the company description\n",
        "        description_text = description_element.text.strip()\n",
        "\n",
        "        # Extract the link URL\n",
        "        link_element = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CLASS_NAME, \"About_text__mxRe_\")))\n",
        "        link_url = link_element.get_attribute(\"href\")\n",
        "\n",
        "        # Use BeautifulSoup to parse the HTML content\n",
        "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "        company_name_element = soup.find('h1', class_='header_title__Zb2Pc')\n",
        "        if company_name_element:\n",
        "            company_name = company_name_element.text.strip()\n",
        "        else:\n",
        "            company_name = None\n",
        "        # Extract industry, funding, and people information based on href attributes\n",
        "        industry_element = soup.find('a', href=lambda href: href and href.startswith(\"/industries\"))\n",
        "        funding_element = soup.find('a', href=lambda href: href and href.startswith(\"/companies/funding-sources/\"))\n",
        "        people_element = soup.find('a', href=lambda href: href and href.startswith(\"/companies/sizes/\"))\n",
        "\n",
        "        # Extract the text content\n",
        "        industry = industry_element.text.strip() if industry_element else None\n",
        "        funding = funding_element.text.strip() if funding_element else None\n",
        "        people = people_element.text.strip() if people_element else None\n",
        "\n",
        "        return {\n",
        "\n",
        "            \"repvue_url\": url,\n",
        "            \"company_url\": link_url,\n",
        "            \"Company Name\": company_name,\n",
        "            \"Description\": description_text,\n",
        "            \"employee_count\": people,\n",
        "            \"Funding\": funding,\n",
        "            \"Industry\": industry,\n",
        "             }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred for URL '{url}': {e}\")\n",
        "        return None\n",
        "\n",
        "    finally:\n",
        "        driver.quit()\n",
        "\n",
        "# Read URLs from Excel file\n",
        "df_urls = pd.read_excel('/content/Book4.xlsx', sheet_name='Sheet1', engine='openpyxl')  # Replace 'your_file.xlsx' with your Excel file path and sheet name\n",
        "\n",
        "# Extract URLs from a specific column in the DataFrame\n",
        "url_list = df_urls['url'].tolist()\n",
        "\n",
        "# Process each URL and store the results\n",
        "results = []\n",
        "for url in url_list:\n",
        "    result = process_url(url)\n",
        "    if result:\n",
        "        results.append(result)\n",
        "\n",
        "# Create a DataFrame from the results\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# Save the DataFrame to a new Excel file\n",
        "output_file = 'extracted_data.xlsx'\n",
        "df_results.to_excel(output_file, index=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df_results)\n",
        "\n",
        "# Display the path to the output file\n",
        "print(f\"Data has been extracted and saved to '{output_file}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the extracted data from the Excel file\n",
        "input_file = 'extracted_data.xlsx'\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Clean up the description format by removing extra spaces and line breaks\n",
        "df['Description'] = df['Description'].apply(lambda x: ' '.join(x.split()) if isinstance(x, str) else x)\n",
        "\n",
        "# Save the cleaned DataFrame back to the Excel file\n",
        "output_file_cleaned = 'extracted_data_cleaned.xlsx'\n",
        "df.to_excel(output_file_cleaned, index=False)\n",
        "\n",
        "# Display the path to the cleaned output file\n",
        "print(f\"Cleaned data has been saved to '{output_file_cleaned}'.\")\n",
        "\n",
        "# Display the first few rows of the cleaned DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "zrtyZJBiLYFX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}