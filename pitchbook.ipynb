{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt-get install chromium chromium-driver"
      ],
      "metadata": {
        "id": "-22ho3LsOD-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nUvfhIsN6NV"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import time\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def web_driver():\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--verbose\")\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--disable-gpu')\n",
        "    options.add_argument(\"--window-size=1920,1200\")\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
        "\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    return driver\n",
        "\n",
        "def process_url(url):\n",
        "    driver = web_driver()\n",
        "\n",
        "    try:\n",
        "        driver.get(url)\n",
        "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"pp-overview-item__title\")))\n",
        "        page_source = driver.page_source\n",
        "        soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "        company_name_element = soup.find('div', class_='pp-logo-company')\n",
        "        if company_name_element:\n",
        "            company_name = company_name_element.find('img')['alt']\n",
        "        else:\n",
        "            company_name = \"Company name not found\"\n",
        "\n",
        "        year_founded_element = soup.find('li', text='Year Founded')\n",
        "        year_founded = year_founded_element.find_next('span', class_='pp-overview-item__title').get_text(strip=True)\n",
        "\n",
        "        employees_element = soup.find('li', text='Employees')\n",
        "        employees = employees_element.find_next('span', class_='pp-overview-item__title').get_text(strip=True)\n",
        "\n",
        "        description_element = soup.find('p', class_='pp-description_title')\n",
        "        description = description_element.get_text(strip=True) if description_element else \"Description not found\"\n",
        "\n",
        "        website_element = soup.find('h5', text='Website')\n",
        "        website_url = website_element.find_next('a')['href'] if website_element else \"Website URL not found\"\n",
        "\n",
        "\n",
        "\n",
        "        #ownership_status_element = soup.find('div', class_='font-weight-normal')\n",
        "        #ownership_status = ownership_status_element.get_text(strip=True) if ownership_status_element else \"Ownership status not found\"\n",
        "        # Find the <p> element containing the funding information\n",
        "        # Extract Funding\n",
        "        ul_tag = soup.find('ul', class_='list-type-none pp-faqs-table')\n",
        "\n",
        "        if ul_tag:\n",
        "    # Find all <p> tags within the <ul> tag\n",
        "            p_tags = ul_tag.find_all('p', class_='XL-7 M-12 mb-xl-0')\n",
        "\n",
        "            for p_tag in p_tags:\n",
        "        # Extract the text content of each <p> tag\n",
        "                text_content = p_tag.get_text(strip=True)\n",
        "\n",
        "        # Check if the text content contains the funding information\n",
        "                if \"raised $\" in text_content:\n",
        "                    funding_info = text_content\n",
        "                if \"industry\" in text_content:\n",
        "                    industry_info = text_content\n",
        "\n",
        "                if \"competitor\" in text_content:\n",
        "                    competitors_info = text_content\n",
        "                else:\n",
        "                    competitors_info = \"not found\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        data = {\n",
        "            'URL': url,\n",
        "            'Company Name': company_name,\n",
        "            'Year Founded': year_founded,\n",
        "            'Employees': employees,\n",
        "            'Description': description,\n",
        "            'Website': website_url,\n",
        "            \"funding_amount\" :funding_info,\n",
        "            \"industry\" : industry_info,\n",
        "            \"competitors\" :competitors_info\n",
        "            }\n",
        "\n",
        "        return data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing URL: {url}\")\n",
        "        print(f\"Error message: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    finally:\n",
        "        driver.quit()\n",
        "#add path here of csv file\n",
        "csv_file_path = '/content/Lead data - pitchbook_output.csv'\n",
        "data_list = []\n",
        "with open(csv_file_path, newline='') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "        url = row['link'].strip()\n",
        "        if url.startswith('https://pitchbook.com'):\n",
        "            print(f\"Processing URL: {url}\")\n",
        "            data = process_url(url)\n",
        "            if data:\n",
        "                data_list.append(data)\n",
        "            print(\"Completed processing for:\", url)\n",
        "            print(\"-\" * 50)\n",
        "            time.sleep(2)\n",
        "\n",
        "df = pd.DataFrame(data_list)\n",
        "\n",
        "output_csv_path = 'output_data.csv'\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "print(f\"Data saved to {output_csv_path}\")\n",
        "\n",
        "print(df)\n"
      ]
    }
  ]
}